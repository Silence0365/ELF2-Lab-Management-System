# ======================== ReadMe ========================
# æºä»£ç å¼•ç”¨ï¼š
# é¡¹ç›®å    ï¼šrknn_model_zoo
# ä½œè€…      ï¼šRockchip AI Team (GitHub: @airockchip)
# æºä»“åº“    ï¼šhttps://github.com/airockchip/rknn_model_zoo
# æ–‡ä»¶è·¯å¾„  ï¼šexamples/whisper/python/whisper.py
# å¼•ç”¨æ—¶é—´  ï¼š2025-07-03
# å¼•ç”¨ç›®çš„  ï¼šå‚è€ƒ Whisper æ¨¡å‹çš„ RKNN åŠ è½½ä¸æ¨ç†æµç¨‹,éƒ¨ç½²Flaskä»¥é…åˆå‰ç«¯å®ç°è¯­éŸ³è½¬æ–‡å­—è¾“å…¥åŠŸèƒ½
# ä¿®æ”¹è¯´æ˜  ï¼šæ ¹æ®æœ¬åœ°éƒ¨ç½²éœ€æ±‚é€‚é… Flask æ¥å£ã€åŠ å…¥éŸ³é¢‘ä¸Šä¼ ä¸ä¸­æ–‡è¯†åˆ«ã€æ”¯æŒ encoder + decoder åˆ†æ¨¡å‹åŠ è½½
# License   ï¼šApache License 2.0
# ======================== ReadMe ========================


from flask import Flask, request, jsonify
import numpy as np
import torch
import torch.nn.functional as F
import scipy
import onnxruntime
from rknnlite.api import RKNNLite
from pydub import AudioSegment
from flask_cors import CORS
import io
from werkzeug.utils import secure_filename

app = Flask(__name__)
CORS(app)

# å‚æ•°
SAMPLE_RATE = 16000
N_FFT = 400
HOP_LENGTH = 160
CHUNK_LENGTH = 20
MAX_LENGTH = CHUNK_LENGTH * 100
N_MELS = 80

# base64 è§£ç å‡½æ•°
def get_char_index(c):
    if 'A' <= c <= 'Z':
        return ord(c) - ord('A')
    elif 'a' <= c <= 'z':
        return ord(c) - ord('a') + 26
    elif '0' <= c <= '9':
        return ord(c) - ord('0') + 52
    elif c == '+':
        return 62
    elif c == '/':
        return 63
    else:
        raise ValueError(f"Unknown base64 character: {c}")

def base64_decode(encoded_string):
    if not encoded_string:
        return ""
    output_bytes = bytearray()
    i = 0
    while i < len(encoded_string):
        if encoded_string[i] == '=':
            break
        b1 = get_char_index(encoded_string[i])
        b2 = get_char_index(encoded_string[i+1])
        output_bytes.append((b1 << 2) | (b2 >> 4))
        if encoded_string[i+2] == '=':
            break
        b3 = get_char_index(encoded_string[i+2])
        output_bytes.append(((b2 & 0xF) << 4) | (b3 >> 2))
        if encoded_string[i+3] == '=':
            break
        b4 = get_char_index(encoded_string[i+3])
        output_bytes.append(((b3 & 0x3) << 6) | b4)
        i += 4
    return output_bytes.decode('utf-8', errors='replace')

# æ¨¡å‹åŠ è½½ä¸æ¨ç†
def init_model(model_path):
    if model_path.endswith(".rknn"):
        model = RKNNLite()
        ret = model.load_rknn(model_path)
        if ret != 0:
            raise RuntimeError(f"Load RKNN model \"{model_path}\" failed!")
        ret = model.init_runtime()
        if ret != 0:
            raise RuntimeError("RKNN runtime init failed")
    else:
        model = onnxruntime.InferenceSession(model_path, providers=['CPUExecutionProvider'])
    return model

def release_model(model):
    if isinstance(model, RKNNLite):
        model.release()

def run_encoder(model, x):
    if isinstance(model, RKNNLite):
        return model.inference(inputs=x)[0]
    else:
        return model.run(None, {"x": x})[0]

def _decode(model, tokens, enc_out):
    tokens_np = np.asarray([tokens], dtype="int64")
    inputs = [tokens_np, enc_out]
    out = model.inference(inputs=inputs)
    if out is None:
        raise RuntimeError("âŒ Decoder æ¨ç†å¤±è´¥ï¼Œè¿”å› Noneï¼Œå¯èƒ½æ˜¯ tokens å¤ªé•¿")
    return out[0]

def run_decoder(model, enc_out, vocab, task_code):
    end_token = 50257
    timestamp_begin = 50364
    tokens = [50258, task_code, 50359, 50363]
    tokens = tokens * 3
    max_tokens = 12
    pop_id = max_tokens
    tokens_str = ''
    next_token = 50258

    while next_token != end_token:
        out_decoder = _decode(model, tokens, enc_out)
        next_token = out_decoder[0, -1].argmax()
        next_token_str = vocab.get(str(next_token), "")
        tokens.append(next_token)

        if next_token == end_token:
            tokens.pop(-1)
            break
        if next_token > timestamp_begin:
            continue
        if pop_id > 4:
            pop_id -= 1
        tokens.pop(pop_id)
        tokens_str += next_token_str

    result = tokens_str.replace('\u0120', ' ').replace('<|endoftext|>', '').replace('\n', '')
    return result.strip()

def read_vocab(path):
    vocab = {}
    with open(path, 'r') as f:
        for line in f:
            parts = line.strip().split(' ', 1)
            if len(parts) == 2:
                vocab[parts[0]] = parts[1]
            else:
                vocab[parts[0]] = ''
    return vocab

# ç‰¹å¾æå–
def mel_filters(n_mels):
    filters_path = "../model/mel_80_filters.txt"
    mels_data = np.loadtxt(filters_path, dtype=np.float32).reshape((n_mels, 201))
    return torch.from_numpy(mels_data)

def log_mel_spectrogram(audio, n_mels):
    if not torch.is_tensor(audio):
        audio = torch.from_numpy(audio)
    window = torch.hann_window(N_FFT)
    stft = torch.stft(audio, N_FFT, HOP_LENGTH, window=window, return_complex=True)
    magnitudes = stft[..., :-1].abs() ** 2
    filters = mel_filters(n_mels)
    mel_spec = filters @ magnitudes
    log_spec = torch.clamp(mel_spec, min=1e-10).log10()
    log_spec = torch.maximum(log_spec, log_spec.max() - 8.0)
    log_spec = (log_spec + 4.0) / 4.0
    return log_spec

def pad_or_trim(mel, length=MAX_LENGTH):
    if mel.shape[1] < length:
        mel = np.pad(mel, ((0, 0), (0, length - mel.shape[1])), constant_values=0)
    elif mel.shape[1] > length:
        mel = mel[:, :length]
    return mel

# ========== Whisper æ¨ç†æ¥å£ ==========
@app.route('/whisper', methods=['POST'])
def whisper():
    if 'file' not in request.files:
        return jsonify({'error': 'No file part'}), 400

    file = request.files['file']
    filename = secure_filename(file.filename)
    file_ext = filename.split('.')[-1].lower()
    file_bytes = file.read()

    # âœ… è‡ªåŠ¨åˆ¤æ–­ webm æˆ–å…¶ä»–æ ¼å¼
    try:
        if file_ext == "webm":
            audio = AudioSegment.from_file(io.BytesIO(file_bytes), format="webm")
        else:
            audio = AudioSegment.from_file(io.BytesIO(file_bytes))  # å°è¯•è‡ªåŠ¨è¯†åˆ«
        audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)
        audio_np = np.array(audio.get_array_of_samples()).astype(np.float32) / 32768.0
    except Exception as e:
        return jsonify({'error': f'éŸ³é¢‘è§£æå¤±è´¥: {str(e)}'}), 500

    # ç‰¹å¾æå–
    x_mel = log_mel_spectrogram(audio_np, N_MELS).numpy()
    x_mel = pad_or_trim(x_mel)
    x_mel = np.expand_dims(x_mel, 0)

    # åŠ è½½æ¨¡å‹
    encoder_model = init_model('/home/elf/Desktop/Project/AI/whisper/rknn_whisper_demo/model/whisper_encoder_base_20s.rknn')#encoderè·¯å¾„
    decoder_model = init_model('/home/elf/Desktop/Project/AI/whisper/rknn_whisper_demo/model/whisper_decoder_base_20s.rknn')#decoderè·¯å¾„
    vocab = read_vocab('/home/elf/Desktop/Project/AI/whisper/rknn_whisper_demo/model/vocab_zh.txt')#vocabè·¯å¾„-->ä¸­æ–‡éœ€å¯¹åº”ä¸­æ–‡çš„vocab

    # æ¨ç†
    out_encoder = run_encoder(encoder_model, x_mel)
    result = run_decoder(decoder_model, out_encoder, vocab, task_code=50260)
    print("ğŸ“ æ¨ç†ç»“æœ(ç¼–ç ):", result)

    # base64 è§£ç 
    result = base64_decode(result)
    print("ğŸ“ æ¨ç†ç»“æœ(è§£ç å):", result)

    release_model(encoder_model)
    release_model(decoder_model)

    return jsonify({'transcript': result})

# å¯åŠ¨æœåŠ¡
if __name__ == '__main__':
    app.run(debug=False, host="0.0.0.0", port=5000)
